{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Custom Gradient Functions in TensorFlow\n\nThis notebook demonstrates how to implement custom gradient functions in TensorFlow using the [`@tf.custom_gradient`](https://www.tensorflow.org/api_docs/python/tf/custom_gradient) decorator.\n\n## Why Custom Gradients?\n\nCustom gradients are essential for differentiable programming because they allow us to:\n\n- **Define gradients for non-differentiable functions** (like sign, argmax, etc.)\n- **Improve numerical stability** by providing more stable gradient computations\n- **Implement domain-specific optimizations** for gradient calculations\n- **Create differentiable approximations** of discrete operations\n- **Control gradient flow** in complex computational graphs\n\nThis is a fundamental tool for making traditionally non-differentiable algorithms learnable through backpropagation."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Chain Rule Fundamentals\n\nBefore diving into custom gradients, let's review how the chain rule works in automatic differentiation.\n\nConsider a function $f(x) = x^2$, and we compose it as $y = f(f(f(x)))$. To find $\\frac{dy}{dx}$, we decompose this into intermediate variables:\n\n\\begin{align}\n  y &= x_0^2\\\\\n  x_0 &= x_1^2\\\\\n  x_1 &= x^2\n\\end{align}\n\nTaking first-order derivatives of each step:\n\n\\begin{align}\n  \\frac{dy}{dx_0} &= 2x_0\\\\\n  \\frac{dx_0}{dx_1} &= 2x_1\\\\\n  \\frac{dx_1}{dx} &= 2x\n\\end{align}\n\nApplying the chain rule:\n\n$$\\frac{dy}{dx} = \\frac{dy}{dx_0} \\cdot \\frac{dx_0}{dx_1} \\cdot \\frac{dx_1}{dx}$$\n\n**General Form**: For a computational graph with $n$ intermediate steps:\n\n$$\\frac{dy}{dx} = \\frac{dy}{dx_{0}} \\prod_{i=0}^{n-1} \\frac{dx_i}{dx_{i+1}}$$"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### TensorFlow's Gradient Flow Mechanism\n\nIn TensorFlow's automatic differentiation, gradients flow backward through the computational graph. Each function receives an **upstream gradient** and computes a **downstream gradient**.\n\n**Upstream Gradient**: The gradient flowing from later operations in the graph:\n$$\\text{upstream} = \\frac{dy}{dx_{i-1}} = \\frac{dy}{dx_{i-2}} \\cdot \\frac{dx_{i-2}}{dx_{i-1}}$$\n\n**Current Function Gradient**: The local gradient of the current operation:\n$$\\frac{dx_i}{dx_{i+1}}$$\n\n**Downstream Gradient**: The product passed to earlier operations:\n$$\\text{downstream} = \\frac{dx_i}{dx_{i+1}} \\times \\text{upstream}$$\n\nThis mechanism allows each operation to contribute its local gradient while preserving the chain rule structure. Custom gradients integrate seamlessly into this flow by implementing the `grad` function that receives upstream gradients and returns downstream gradients."
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Basic Custom Gradient Implementation\n\nLet's implement a simple custom gradient for $f(x) = x^2$. The debug prints will show how gradients flow backward through nested function calls:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Multi-Variable Custom Gradients\n\nFor functions with multiple inputs, the custom gradient function must return gradients for each input variable in the same order as the function parameters.\n\n### Example: Product Function\nFor $z = f(x,y) = xy$, we have:\n- $\\frac{\\partial z}{\\partial x} = y$\n- $\\frac{\\partial z}{\\partial y} = x$\n\nThe gradient function returns `(upstream * y, upstream * x)` to properly distribute the upstream gradient to both input variables.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=2.0\ty=4.0\n",
      "x=4.0\ty=16.0\n",
      "x=16.0\ty=256.0\n",
      "x=16.0\tupstream=1.0\tcurrent=32.0\t\tdownstream=32.0\n",
      "x=4.0\tupstream=32.0\tcurrent=8.0\t\tdownstream=256.0\n",
      "x=2.0\tupstream=256.0\tcurrent=4.0\t\tdownstream=1024.0\n",
      "\n",
      "final dy/dx=1024.0\n"
     ]
    }
   ],
   "source": [
    "# @tf.function\n",
    "@tf.custom_gradient\n",
    "def foo(x):\n",
    "    tf.debugging.assert_rank(x, 0)\n",
    "\n",
    "    def grad(dy_dx_upstream):\n",
    "        dy_dx = 2 * x\n",
    "        dy_dx_downstream = dy_dx * dy_dx_upstream\n",
    "        tf.print(f'x={x}\\tupstream={dy_dx_upstream}\\tcurrent={dy_dx}\\t\\tdownstream={dy_dx_downstream}')\n",
    "        return dy_dx_downstream\n",
    "    \n",
    "    y = x ** 2\n",
    "    tf.print(f'x={x}\\ty={y}')\n",
    "    \n",
    "    return y, grad\n",
    "\n",
    "\n",
    "x = tf.constant(2.0, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    y = foo(foo(foo(x))) # y = x ** 8\n",
    "\n",
    "tf.print(f'\\nfinal dy/dx={tape.gradient(y, x)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Practical Application: Differentiable Approximations\n\nOne of the most powerful applications of custom gradients is making non-differentiable functions differentiable by providing smooth approximations for the backward pass.\n\n### Case Study: Differentiable Sign Function\n\nThe sign function is non-differentiable:\n\n$$\\text{sign}(x) = \\begin{cases}\n  -1, & \\text{if } x < 0 \\\\\n  0, & \\text{if } x = 0 \\\\\n  1, & \\text{if } x > 0\n\\end{cases}$$\n\n**Strategy**: Keep the discrete sign function in the forward pass, but use a smooth approximation for gradients.\n\n**Gradient Approximation**: We use the sigmoid derivative:\n$$\\frac{d\\text{sign}_{\\text{approx}}(x)}{dx} = \\sigma(x)(1 - \\sigma(x))$$\n\nwhere $\\sigma(x) = \\frac{1}{1 + e^{-x}}$ is the sigmoid function.\n\n**Why This Works**: \n- Forward pass maintains the exact discrete behavior we want\n- Backward pass provides smooth gradients that enable optimization\n- The sigmoid derivative is bell-shaped, providing strongest gradients near $x=0$ where the sign function transitions",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients with multiple variables\n",
    "\n",
    "If the function takes multiple variables, then the gradient for each variable has to be returned as demonstrated in the example."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Testing the Differentiable Sign Function\n\nLet's test our differentiable sign function:\n- **Forward pass**: `sign(3.0) = 1.0` (correct discrete behavior)\n- **Gradient**: `â‰ˆ 0.045` (smooth, non-zero gradient enables optimization)\n- **Loss computation**: We can compute loss and its gradient, enabling training!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Training with the Differentiable Sign Function\n\nNow let's train a parameter to minimize the loss `L = ||sign(x) - 1||Â²`. We start with `x = -1` and want to find `x` such that `sign(x) = 1`.\n\n**Expected Behavior**: The optimizer should drive `x` toward positive values to make `sign(x) = 1`.\n\n**Key Insight**: Without the custom gradient, this would be impossible because `sign(x)` has zero gradient almost everywhere. With our smooth approximation, the optimizer can \"see\" which direction to move!",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Training Success! ðŸŽ‰\n\nPerfect results! The training shows:\n\n1. **Initial State**: `x = -1`, `sign(x) = -1`, `loss = 2`\n2. **Optimization**: Gradients guide `x` toward positive values\n3. **Final State**: `x â‰ˆ 0.99`, `sign(x) = 1`, `loss = 0`\n\n**Key Achievements**:\n- âœ… **Non-differentiable function made trainable**: Sign function integrated into gradient-based optimization\n- âœ… **Discrete behavior preserved**: Forward pass maintains exact sign function behavior  \n- âœ… **Smooth optimization**: Custom gradients enable efficient parameter updates\n- âœ… **Perfect convergence**: Loss reaches zero, target behavior achieved\n\n## Summary\n\nCustom gradients are essential for differentiable programming because they enable:\n\n1. **Making discrete operations continuous** for optimization\n2. **Maintaining exact forward behavior** while providing smooth gradients\n3. **Integrating non-differentiable functions** into neural network architectures\n4. **Enabling end-to-end training** of complex algorithms\n\nThis technique is fundamental to many advanced differentiable programming applications, from differentiable sorting to program synthesis!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "2\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "@tf.custom_gradient\n",
    "def bar(x, y):\n",
    "    tf.debugging.assert_rank(x, 0)\n",
    "    tf.debugging.assert_rank(y, 0)\n",
    "\n",
    "    def grad(upstream):\n",
    "        dz_dx = y\n",
    "        dz_dy = x\n",
    "        return upstream * dz_dx, upstream * dz_dy\n",
    "    \n",
    "    z = x * y\n",
    "    \n",
    "    return z, grad\n",
    "\n",
    "x = tf.constant(2.0, dtype=tf.float32)\n",
    "y = tf.constant(3.0, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    tape.watch(y)\n",
    "    z = bar(x, y)\n",
    "\n",
    "tf.print(z)\n",
    "tf.print(tape.gradient(z, x))\n",
    "tf.print(tape.gradient(z, y))\n",
    "tf.print(tape.gradient(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of custom gradients\n",
    "\n",
    "### Toy example: Differentiable approximation of non-differentiable functions\n",
    "\n",
    "We take the sign function as an example\n",
    "\n",
    "\\begin{equation}\n",
    "sign(x)= \\\\\n",
    "\\begin{cases}\n",
    "  -1, & \\text{if}\\ x<0 \\\\\n",
    "  0, & \\text{if}\\ x=0 \\\\\n",
    "  1, & \\text{if}\\ x>0 \\\\\n",
    "\\end{cases}\\end{equation}\n",
    "  \n",
    "By implementing a custom gradient, we can continue to have the $sign(x)$ function in forward pass but a differentiable approximation in the backward pass. In this case we approximate $sign(x)$ with the sigmoid function $ \\sigma(x)$\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dsign_{approx}(x)}{dx} = \\sigma(x) (1 - \\sigma(x)) \\\\\n",
    "sign_{approx}(x) = \\sigma(x) + C \\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.0451766551\n",
      "2\n",
      "0.0903533101\n"
     ]
    }
   ],
   "source": [
    "# @tf.function\n",
    "@tf.custom_gradient\n",
    "def differentiable_sign(x):\n",
    "    tf.debugging.assert_rank(x, 0)\n",
    "\n",
    "    def grad(upstream):\n",
    "        dy_dx = tf.math.sigmoid(x) * (1 - tf.math.sigmoid(x))\n",
    "        return upstream * dy_dx\n",
    "    \n",
    "    if x > tf.constant(0.0):\n",
    "        return tf.constant(1.0), grad\n",
    "    else:\n",
    "        return tf.constant(-1.0), grad\n",
    "\n",
    "\n",
    "x = tf.constant(3.0, dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    tape.watch(x)\n",
    "    y = differentiable_sign(x)\n",
    "    loss = tf.nn.l2_loss(y - tf.constant(-1.0))\n",
    "    \n",
    "tf.print(y)\n",
    "tf.print(tape.gradient(y, x))\n",
    "tf.print(loss)\n",
    "tf.print(tape.gradient(loss, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 -0.393223882 -0.89999783 -1\n",
      "10 0 0 0.0995881185 1\n",
      "20 0 0 0.6450876 1\n",
      "30 0 0 0.855591536 1\n",
      "40 0 0 0.938390434 1\n",
      "50 0 0 0.970632374 1\n",
      "60 0 0 0.983009696 1\n",
      "70 0 0 0.987700462 1\n",
      "80 0 0 0.989459515 1\n",
      "90 0 0 0.990113616 1\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(-1.0)\n",
    "opt = tf.keras.optimizers.Adam(1e-1)\n",
    "# opt = tf.keras.optimizers.SGD(1)\n",
    "\n",
    "def train_step():\n",
    "    with tf.GradientTape() as tape:\n",
    "        y = differentiable_sign(x)\n",
    "        loss = tf.nn.l2_loss(y - tf.constant(1.0))\n",
    "    grads = tape.gradient(loss, x)\n",
    "    opt.apply_gradients(zip([grads], [x]))\n",
    "    return loss, y, grads\n",
    "\n",
    "for i in range(100):\n",
    "    loss, y, grads = train_step()\n",
    "    if i % 10 == 0:\n",
    "        tf.print(i, loss, grads, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}